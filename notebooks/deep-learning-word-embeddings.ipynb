{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"we are learning word2vec\",\n",
    "    \"word2vec is fun to learn\",\n",
    "    \"we learn from examples\",\n",
    "    \"examples make learning word2vec easier\"\n",
    "]\n",
    "\n",
    "# Hyperparameters\n",
    "window_size = 2\n",
    "embedding_dim = 50\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Preprocessing\n",
    "def tokenize_corpus(corpus):\n",
    "    tokenized_corpus = [sentence.split() for sentence in corpus]\n",
    "    vocab = {word for sentence in tokenized_corpus for word in sentence}\n",
    "    word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "    idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
    "    return tokenized_corpus, word_to_idx, idx_to_word\n",
    "\n",
    "def generate_context_target_pairs(tokenized_corpus, window_size):\n",
    "    context_target_pairs = []\n",
    "    for sentence in tokenized_corpus:\n",
    "        for i, word in enumerate(sentence):\n",
    "            for j in range(max(0, i - window_size), min(len(sentence), i + window_size + 1)):\n",
    "                if i != j:\n",
    "                    context_target_pairs.append((word, sentence[j]))\n",
    "    return context_target_pairs\n",
    "\n",
    "tokenized_corpus, word_to_idx, idx_to_word = tokenize_corpus(corpus)\n",
    "context_target_pairs = generate_context_target_pairs(tokenized_corpus, window_size)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "class Word2VecDataset(Dataset):\n",
    "    def __init__(self, context_target_pairs, word_to_idx):\n",
    "        self.pairs = context_target_pairs\n",
    "        self.word_to_idx = word_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        context_word, target_word = self.pairs[index]\n",
    "        return self.word_to_idx[context_word], self.word_to_idx[target_word]\n",
    "\n",
    "dataset = Word2VecDataset(context_target_pairs, word_to_idx)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Word2Vec Model\n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context_word):\n",
    "        embeds = self.embeddings(context_word)\n",
    "        out = self.linear(embeds)\n",
    "        return out\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "vocab_size = len(word_to_idx)\n",
    "model = Word2Vec(vocab_size, embedding_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for context_word, target_word in dataloader:\n",
    "        context_word, target_word = context_word.long(), target_word.long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(context_word)\n",
    "        loss = criterion(output, target_word)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Extract embeddings\n",
    "word_embeddings = model.embeddings.weight.data.numpy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
